{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e82993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01607ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c415f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download ('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = nltk.corpus.gutenberg\n",
    "print (\"Gutenberg files:\", gb.fileids ())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth = nltk.corpus.gutenberg.words ('shakespeare-macbeth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len (macbeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bfb4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth [:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc956543",
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_sents = nltk.corpus.gutenberg.sents ('shakespeare-macbeth.txt')\n",
    "macbeth_sents [: 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04203cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(macbeth)\n",
    "text.concordance('Stage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.common_contexts(['Stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4cec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.similar('Stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(macbeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5038fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa394fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(nltk.corpus.stopwords.words ('english'))\n",
    "print(len(sw))\n",
    "list(sw) [:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4476e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_filtered = [w for w in macbeth if w.lower() not in sw]\n",
    "fd = nltk.FreqDist (macbeth_filtered)\n",
    "fd.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctuation = set (string.punctuation)\n",
    "macbeth_filtered2 = [w.lower () for w in macbeth if w.lower () not in sw and w.lower () not in punctuation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e84dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist (macbeth_filtered2)\n",
    "fd.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_words = [w for w in macbeth if len(w)> 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b50724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious_words = [w for w in macbeth if 'ious' in w]\n",
    "ious_words = set(ious_words)\n",
    "sorted(ious_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgrms = nltk.FreqDist(nltk.bigrams(macbeth_filtered2))\n",
    "bgrms.most_common(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857337f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgrms = nltk.FreqDist(nltk.trigrams (macbeth_filtered2))\n",
    "tgrms.most_common(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b5e40",
   "metadata": {},
   "source": [
    "# Preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e43ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'This is a Demo Sentence'\n",
    "lower_text = text.lower()\n",
    "lower_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "text = 'This is a Demo Sentence'\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'This is a Demo Sentence. This is another sentence'\n",
    "tokens = nltk.sent_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "text = 'This% is a #!!@ Sentence full of punctuation marks :-) '\n",
    "regexpt = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "tokens = regexpt.tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = 'This is a Demo Sentence. This is another sentence'\n",
    "eng_sw = stopwords.words('english')\n",
    "tokens = nltk.word_tokenize(text)\n",
    "clean_tokens = [word for word in tokens if word not in eng_sw]\n",
    "clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9be7f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'oper', 'oper', 'for', 'the', 'oper', 'curios', '.', 'a', 'decis', 'decis']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "text = 'This operation operates for the operator curiosity. A decisive decision'\n",
    "stemmer = SnowballStemmer('english')\n",
    "tokens = nltk.word_tokenize(text)\n",
    "stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "print(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ff863c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'verb', ':', 'I', 'split', ',', 'it', 'split', '.', 'Splitted', 'verb', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nelli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nelli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "text = 'A verb: I split, it splits. Splitted verbs.'\n",
    "tokens = nltk.word_tokenize(text)\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "lemma_tokens = [lmtzr.lemmatize(word) for word in tokens]\n",
    "print(lemma_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291d09f",
   "metadata": {},
   "source": [
    "# Use Text on the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d116d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951452f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d33e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = request.urlopen(url).read().decode('utf8')\n",
    "html[:120]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75389c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html, \"lxml\").get_text()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "text = nltk.Text(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5738d8",
   "metadata": {},
   "source": [
    "# Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e304175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb31a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "reviews = nltk.corpus.movie_reviews\n",
    "documents = [(list(reviews.words(fileid)), category)\n",
    "                for category in reviews.categories()\n",
    "          for fileid in reviews.fileids(category)]\n",
    "random.shuffle(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f40cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_review = ' '.join(documents[0][0])\n",
    "print(first_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b69d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in reviews.words())\n",
    "word_features = list(all_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, word_features):\n",
    "     document_words = set(document)\n",
    "     features = {}\n",
    "     for word in word_features:\n",
    "         features ['{}'.format(word)] = (word in document_words)\n",
    "     return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d,word_features), c) for (d,c) in documents]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dd82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, est_set = featuresets[1500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeab7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58de45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a584acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
